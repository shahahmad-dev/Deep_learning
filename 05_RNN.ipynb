{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **`RNN (Recurrent Neural Network)`**"
      ],
      "metadata": {
        "id": "KZiAv7mb8qsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxkqHhZ-8BAf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the data\n",
        "X = np.random.rand(100, 10, 1)\n",
        "y = np.random.randint(0, 2, size=(100))"
      ],
      "metadata": {
        "id": "D1u1PIZe9jtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "c1TBKQ4c-f9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(10, 1)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "-ZJvnW_W-nhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FudLkyKn_Bxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X, y, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "aKMyIzzF_kXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X,y)\n",
        "print('Test Loss', loss)\n",
        "print('Test Accuracy', accuracy)"
      ],
      "metadata": {
        "id": "2Jb_s54t_6oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**`LSTM (Long Short-Term Memory)`**"
      ],
      "metadata": {
        "id": "VRLdUa6bAaFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorboard as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# load the data\n",
        "flights = sns.load_dataset('flights')\n",
        "\n",
        "# Convert data into time series\n",
        "df = pd.DataFrame({'values': flights['passengers'].values},\n",
        "                   index=pd.date_range(start= '1949-01-01',\n",
        "                   end= '1960-12-01',\n",
        "                   freq='MS'))"
      ],
      "metadata": {
        "id": "uzub6jUkAQYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hCJ-PTNlEWQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.head"
      ],
      "metadata": {
        "id": "YU6BL2akBGBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into traning and testing\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data, test_data = df.iloc[:train_size], df.iloc[train_size:]\n",
        "\n",
        "# Normalize the data\n",
        "train_mean = train_data.mean()\n",
        "train_std = train_data.std()\n",
        "train_data = (train_data-train_mean) / train_std\n",
        "test_data = (test_data-train_mean) / train_std\n",
        "\n",
        "# Convert data to Sequences\n",
        "def to_sequences(data, seq_length):\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(data)-seq_length-1):\n",
        "    X_seq = data[i:(i+seq_length)].values\n",
        "    X.append(X_seq)\n",
        "    y_seq = data.iloc[i+seq_length].values[0]\n",
        "    y.append(y_seq)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 12\n",
        "X_train , y_train = to_sequences(train_data, seq_length)\n",
        "X_test, y_test = to_sequences(test_data, seq_length)\n",
        "\n",
        "\n",
        "# Reshape input to be [simple , time steps, feature]\n",
        "X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    LSTM(32, input_shape=(seq_length, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "# Complie the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print('Loss ', loss)\n",
        "\n",
        "# Make predications on the test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "rqM_vnAnByI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the predicatied and actual values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2HVDbqKJE66R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**`GRU (Gated Recurrent Unit)`**"
      ],
      "metadata": {
        "id": "IuHmGr3SKM0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# load the filght data from seaborn\n",
        "flights = sns.load_dataset('flights')\n",
        "\n",
        "# Convert data into time series\n",
        "df = pd.DataFrame({'values': flights['passengers'].values},\n",
        "                   index=pd.date_range(start= '1949-01-01',\n",
        "                   end= '1960-12-01',\n",
        "                   freq='MS'))\n",
        "# Split data into traning and testing\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data, test_data = df.iloc[:train_size], df.iloc[train_size:]\n",
        "\n",
        "# Normalize the data\n",
        "train_mean = train_data.mean()\n",
        "train_std = train_data.std()\n",
        "train_data = (train_data-train_mean) / train_std\n",
        "test_data = (test_data-train_mean) / train_std\n",
        "\n",
        "# Convert data to Sequences\n",
        "X_train_gru, y_train_gru = to_sequences(train_data, seq_length)\n",
        "X_test_gru, y_test_gru = to_sequences(test_data, seq_length)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train_gru = np.reshape(X_train_gru, (X_train_gru.shape[0], X_train_gru.shape[1], 1))\n",
        "X_test_gru = np.reshape(X_test_gru, (X_test_gru.shape[0], X_test_gru.shape[1], 1))\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    GRU(32, input_shape=(seq_length, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_gru, y_train_gru, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test_gru, y_test_gru)\n",
        "print('Loss ', loss)\n",
        "\n",
        "# Predicate the data\n",
        "y_pred_gru = model.predict(X_test_gru)"
      ],
      "metadata": {
        "id": "p9qYuu4aJ9LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "plt.plot(y_test_gru, label='Actual')\n",
        "plt.plot(y_pred_gru, label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "eQS5vZxPK1Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0j82EnYVLz2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}